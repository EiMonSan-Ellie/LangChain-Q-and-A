{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QcwPUOfl7PWJ"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_mQJChIktOkB"
   },
   "source": [
    "**Document Used for the Notebook**\n",
    "\n",
    "Using the blog article [The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/) by Jay Alammar. This is a popular, visually-rich guide that explains the core concepts behind the Transformer architecture, which powers most modern NLP models.\n",
    "\n",
    "The article covers key ideas such as:\n",
    "\n",
    "* Self-attention mechanisms\n",
    "* Encoder-decoder structures\n",
    "* Positional encoding\n",
    "* The evolution of Transformers in deep learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Om5gFb1wWvh"
   },
   "source": [
    "###### Installing and Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CzRUP8SBl2-g"
   },
   "outputs": [],
   "source": [
    "!pip install langchain-community langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_WXiA7nFmVmT"
   },
   "outputs": [],
   "source": [
    "!pip install -U langchain langchain-openai langchain-community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zAzZ4foTm4Un"
   },
   "outputs": [],
   "source": [
    "!pip install -U langchain langchain-community huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DwPb_ZWOnPOz"
   },
   "outputs": [],
   "source": [
    "from langchain_community.llms import HuggingFaceHub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8sIg6GDBnYw0"
   },
   "outputs": [],
   "source": [
    "!pip install transformers faiss-cpu sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-XHXgrRVndcY"
   },
   "outputs": [],
   "source": [
    "!pip freeze > requirement.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2F13ALyMnw1o"
   },
   "outputs": [],
   "source": [
    "!pip install -U langchain langchain-community beautifulsoup4 requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gjI5VgLpn0PX"
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "39oOuZhwnwWX"
   },
   "outputs": [],
   "source": [
    "!pip -q uninstall -y langchain langchain-community langchain-openai\n",
    "!pip -q install \"langchain<0.2.0\" beautifulsoup4 requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4hrhnRsxx-8z"
   },
   "source": [
    "Step 1: Loading\n",
    "\n",
    "Specify a DocumentLoader to load in unstructured data as Documents.\n",
    "\n",
    "\n",
    "A WebBaseLoader is used to load all text from HTML webpages into a document format that we can use for NLP tasks\n",
    "\n",
    "Loading the Web Document with LangChain\n",
    "\n",
    "Using LangChain’s WebBaseLoader to load the blog content directly from the URL. This:\n",
    "\n",
    "i. Fetches and parses the webpage\n",
    "\n",
    "ii. Strips out HTML tags\n",
    "\n",
    "iii. Returns clean, readable text stored in the data variable\n",
    "\n",
    "This allows us to work with real-world web content without manual preprocessing.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7LuqPkg8pPfC"
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"http://jalammar.github.io/illustrated-transformer/\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HROwM_KyyfjN"
   },
   "source": [
    "Step 2: Splitting\n",
    "\n",
    "Split the Document into chunks for embedding and vector storage.\n",
    "\n",
    "\n",
    "\n",
    "*   Vector Store: One of the most common ways to store and search over unstructured data is to embed it and store the resulting embedding vectors, and then at query time to embed the unstructured query and retrieve the embedding vectors that are 'most similar' to the embedded query.\n",
    "*   Text Embedding:  It is the process of converting text into a numerical representation, typically a vector (a list of numbers). Each word or subword in the text is mapped to a vector in such a way that similar words or phrases have similar vector representations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cNvhARHEpcyw"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 0) #Chunk Size=500: Each chunk will contain up to 500 characters. Chunk Overlap = 0, no overlap is introducted\n",
    "all_splits = text_splitter.split_documents(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gNLSDmmCzxrF"
   },
   "source": [
    "Step 3: Storing\n",
    "\n",
    "Embedding the contents of each document, then store the embedding and document in a vector store, with the embedding being used to index the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rui-McJPpfZK"
   },
   "outputs": [],
   "source": [
    "# Import FAISS from Langchain Vectorstore\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jLbOIF_ephu6"
   },
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TPhjQdo2pj4A"
   },
   "outputs": [],
   "source": [
    "model_name = \"sentence-transformers/all-mpnet-base-v2\" #to optimize for creating embeddings of sentences & text\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': False} #to prevent normalizaton of the embeddings\n",
    "hf = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iSKoh_FWpuUM"
   },
   "outputs": [],
   "source": [
    " # Creating a vector store\n",
    "vectorstore = FAISS.from_documents(documents=all_splits, embedding=hf) ## hf are the hugging face embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d55L60C008TX"
   },
   "source": [
    "Step 4: Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WuFjmGV0p2v9"
   },
   "outputs": [],
   "source": [
    "question = \"What are transformers?\"\n",
    "docs = vectorstore.similarity_search(question) #searching the vector store for the most relevant document chunks based on the similarity of their embeddings to the query's embedding.\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imFXi-8K1r4y"
   },
   "source": [
    "Step 5: Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8fI9mllkp4ay"
   },
   "outputs": [],
   "source": [
    "question = \"What are transformers?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wQoszV8ip8vS"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"google/flan-t5-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# Define the pipeline\n",
    "hf_pipeline = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, max_length=512)\n",
    "\n",
    "# Wrap the pipeline in LangChain's LLM class\n",
    "llm = HuggingFacePipeline(pipeline=hf_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wwvTNY7fqAug"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(llm,retriever=vectorstore.as_retriever())\n",
    "qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CUxpVs9uqNeH"
   },
   "outputs": [],
   "source": [
    "question = \" What is attention mechanism?\"\n",
    "qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xAkxJUef2eqV"
   },
   "source": [
    "Step 6: Chat\n",
    "\n",
    "Conservation Summary Memory:  summarizes the conversation as it happens and stores the current summary in memory. This memory can then be used to inject the summary of the conversation so far into a prompt/chain. This memory is most useful for longer conversations, where keeping the past message history in the prompt verbatim would take up too many tokens.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AKRb_H2WqoRl"
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fwiztNxhqpNG"
   },
   "outputs": [],
   "source": [
    "memory = ConversationSummaryMemory(\n",
    "    llm=llm,\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sCzrWng2zMA"
   },
   "source": [
    "Conversational Retrieval Chain\n",
    "\n",
    "This is a type of chain for having a conversation based on retrieved documents. This chain takes in chat history (a list of messages) and new questions, and then returns an answer to that question. The algorithm for this chain consists of three parts:\n",
    "\n",
    "Use the chat history and the new question to create a “standalone question”. This is done so that this question can be passed into the retrieval step to fetch relevant documents. If only the new question was passed in, then the relevant context may be lacking. If the whole conversation was passed into retrieval, there may be unnecessary information there that would distract from retrieval.\n",
    "\n",
    "This new standalone question is passed to the retriever, and relevant documents are returned.\n",
    "\n",
    "The retrieved documents are passed to an LLM along with either the new question (default behavior) or the original question and chat history to generate a final response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4dpWjZqxqr7q"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "chat = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DxGhKLZDqs5x"
   },
   "outputs": [],
   "source": [
    "chat(\"Explain self-attention\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xjSyXGfvqu4D"
   },
   "outputs": [],
   "source": [
    "chat(\"What is a gentler approach to transformers?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mnMCEmnJrD8i"
   },
   "outputs": [],
   "source": [
    "chat(\"Where were transformers proposed?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CB04J-HqrMXB"
   },
   "outputs": [],
   "source": [
    "chat(\"What are the different layers in a typical Transformer model?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3DcIhHBPrk_i"
   },
   "outputs": [],
   "source": [
    "chat(\"If the vocabulary is 10,000 words, what would the width of the logits vector?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hlGrPGW1roZ2"
   },
   "outputs": [],
   "source": [
    "chat(\"Explain the training process of a Transformer network in detail\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQkavJRy3l2V"
   },
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "POSq71AOruOm"
   },
   "outputs": [],
   "source": [
    "# 1. Dataset Summary\n",
    "print(f\"Total documents: {len(data)}\")\n",
    "\n",
    "# Extract the text content from each Document object\n",
    "document_lengths = [len(doc.page_content.split()) for doc in data]  # Assuming 'data' is a list of Document objects\n",
    "\n",
    "# Display summary statistics\n",
    "print(f\"Average document length: {sum(document_lengths)/len(document_lengths)} words\")\n",
    "print(f\"Minimum document length: {min(document_lengths)} words\")\n",
    "print(f\"Maximum document length: {max(document_lengths)} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h1EhAACHr0wW"
   },
   "outputs": [],
   "source": [
    "# 2. Text Sample Inspection\n",
    "sample_size = 5\n",
    "print(f\"Displaying {sample_size} sample documents:\")\n",
    "\n",
    "for i in range(min(sample_size, len(data))):\n",
    "    print(f\"\\nSample {i+1}:\")\n",
    "    print(data[i].page_content[:500])  # Display the first 500 characters of each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p2LI0bKnsNyd"
   },
   "outputs": [],
   "source": [
    "# 3. Tokenization\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load tokenizer for FLAN-T5 model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-large\")\n",
    "\n",
    "# Apply tokenizer and check token counts for first few documents\n",
    "tokenized_lengths = [len(tokenizer.tokenize(doc.page_content)) for doc in data]\n",
    "print(f\"Average token length: {sum(tokenized_lengths)/len(tokenized_lengths)} tokens\")\n",
    "print(f\"Minimum token length: {min(tokenized_lengths)} tokens\")\n",
    "print(f\"Maximum token length: {max(tokenized_lengths)} tokens\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fzvUGV88spHe"
   },
   "outputs": [],
   "source": [
    "# 4. Document Distribution Analysis\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the distribution of document lengths (in words) and token lengths\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Document length distribution\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(document_lengths, bins=20, color='skyblue', edgecolor='black')\n",
    "plt.title(\"Document Length Distribution (in Words)\")\n",
    "plt.xlabel(\"Word Count\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "# Token length distribution\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(tokenized_lengths, bins=20, color='lightgreen', edgecolor='black')\n",
    "plt.title(\"Token Length Distribution\")\n",
    "plt.xlabel(\"Token Count\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dT8E-thG3iMA"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gxu3TIvk5nPx"
   },
   "outputs": [],
   "source": [
    "!pip -q install nbconvert\n",
    "!jupyter nbconvert --ClearOutputPreprocessor.enabled=True --LangChain Document Q&A.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 182,
     "status": "ok",
     "timestamp": 1769258016787,
     "user": {
      "displayName": "Ellie Wu",
      "userId": "06449904466312309703"
     },
     "user_tz": -660
    },
    "id": "ly2v1nPR_tTA",
    "outputId": "2c3fd2f8-8539-4c39-e9c7-640ac5a458a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 36K\n",
      "drwxr-xr-x 1 root root 4.0K Jan 24 12:11 .\n",
      "drwxr-xr-x 1 root root 4.0K Jan 24 10:40 ..\n",
      "drwxr-xr-x 4 root root 4.0K Jan 16 14:24 .config\n",
      "drwx------ 5 root root 4.0K Jan 24 12:11 drive\n",
      "-rw-r--r-- 1 root root  13K Jan 24 10:47 requirement.txt\n",
      "drwxr-xr-x 1 root root 4.0K Jan 16 14:24 sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls -lah\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 492,
     "status": "ok",
     "timestamp": 1769258028188,
     "user": {
      "displayName": "Ellie Wu",
      "userId": "06449904466312309703"
     },
     "user_tz": -660
    },
    "id": "5LltKTBR_wHy",
    "outputId": "b93f25f4-06cf-4f4b-caf4-bdaff09bc1de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find: warning: you have specified the global option -maxdepth after the argument -name, but global options are not positional, i.e., -maxdepth affects tests specified before it as well as those specified after it.  Please specify global options before other arguments.\n",
      "/content/drive/MyDrive/Colab Notebooks/LangChain Document Q&A.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/PythonForDataScience_intro-1.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Hands_on_Notebook_NumPy_v1.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Session_Notebook_MovieLens_Case_Study+%283%29 (1).ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Solution_Notebook_Cred_Pay_Case_Study+%282%29.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/PythonVisualization (1).ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Untitled0.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Session_Notebook_MovieLens_Case_Study+%283%29.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/PythonVisualization.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Uber_Case_Study_%281%29_%281%29 (2).ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Uber_Case_Study_%281%29_%281%29 (1).ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Uber_Case_Study_%281%29_%281%29.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Copy of PYF_Project_LearnerNotebook_LowCode_Learner.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/PYF_Project_LearnerNotebook_LowCode_Learner.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Copy of AML_Project_LearnerNotebook_LowCode_Final.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Chapter1_Demo1_flask_chatbot.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Chapter2_Solution (1).ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Chapter2_Demo1_Flan-T5-Chatbot.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Chapter2_Solution.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Case_Study_Used_Car_Price_Prediction (1).ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Hands_on_Optimizing_Neural_Networks-1.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Case_Study_Used_Car_Price_Prediction.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/INN_Learner_Notebook_Low_code_Draft.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/INN_Learner_Notebook_Low_code.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/INN_Learner.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Untitled1.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Color Pixel Theory and Image Representation.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/OpenCV for Images.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Edge Detection and Kernels.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Padding, Strides and Pooling.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/CV_Project_Low_Code_Notebook (4).ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/CV_Project_Low_Code_Notebook (3).ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Untitled2.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/CV_Project_Low_Code_Notebook (2).ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/CV_Project_Full_Code_Notebook.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/CV_Project_Low_Code_Notebook (1).ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/CV_Project_Low_Code_Notebook.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Learning.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Plant_Seedling_Classification using Computer Vision.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Churn Prediction using Neural Network.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Untitled3.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Learner_Notebook_Full_Code.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Untitled4.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/FoodHub Data Analysis.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/AML_Project_LearnerNotebook_LowCode_EllieAssignment (1).ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/AML_Project_LearnerNotebook_LowCode_EllieAssignment.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Credit Card Users Churn Predictions.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/NLP_Project_Low_Code-2 (5).ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/NLP_Project_Low_Code-2 (4).ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/NLP_Project_Low_Code-2 (3).ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/NLP_Project_Low_Code-2 (2).ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Untitled5.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Untitled6.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/NLP_Project_Low_Code-2 (1).ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Untitled7.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/NLP_Project_Low_Code-2.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/3.2Honey_Production_Case_Study.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/3.2Honey_Production.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Untitled8.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Google Play Store Case Study.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Google Play Store.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Uber.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Untitled9.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Cars4u.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/AnimeRatingPrediction_Supervised Linear Regression.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/MLS2_DecisionTree_MachineFailurePrediction.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Machine_Failure_Prediction_DecisionTree.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Loan_Delinquent_DecisionTree.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/IncomeGroupClassification_WHO.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Retail_Customer_Segmentation_KMeans_Clustering.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Product_Segmentation_Clustering.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/GeneAnalysis_Clustering.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/DiabetesRisk_Prediction_Bagging & Random_Forest.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/HR_Attrition_Bagging & Random_Forest.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Ensemble_Boosting.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/WineQuality_Prediction_Boosting.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Bike_Sharing_Boosting.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Job Change Prediction_Model Tuning.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/German_Credit_Analysis_Model Tuning.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Used_Car_Price_Prediction_Neural Network.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Audio_MNIST_Digit_Recognition.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Credit_Card_Fraud_Detection_NN.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Flight_Price_NN.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Untitled10.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Untitled11.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Untitled12.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Untitled13.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Copy of week 3 day 2 - pipelines.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Untitled14.ipynb\n",
      "/content/drive/MyDrive/Colab Notebooks/Untitled15.ipynb\n"
     ]
    }
   ],
   "source": [
    "!find /content -name \"*.ipynb\" -maxdepth 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2653,
     "status": "ok",
     "timestamp": 1769258043566,
     "user": {
      "displayName": "Ellie Wu",
      "userId": "06449904466312309703"
     },
     "user_tz": -660
    },
    "id": "GxjQi7bo_x0Q",
    "outputId": "9af21ed1-40ed-483e-f0d2-c09777c79390"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM0dyCVKJZA7DcHepToQY+F",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
