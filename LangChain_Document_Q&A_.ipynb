{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_mQJChIktOkB"
   },
   "source": [
    "**Document Used for the Notebook**\n",
    "\n",
    "Using the blog article [The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/) by Jay Alammar. This is a popular, visually-rich guide that explains the core concepts behind the Transformer architecture, which powers most modern NLP models.\n",
    "\n",
    "The article covers key ideas such as:\n",
    "\n",
    "* Self-attention mechanisms\n",
    "* Encoder-decoder structures\n",
    "* Positional encoding\n",
    "* The evolution of Transformers in deep learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Om5gFb1wWvh"
   },
   "source": [
    "###### Installing and Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CzRUP8SBl2-g",
    "outputId": "99321cb6-de9e-4faf-fbfd-c0ed31c2d9df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.0.38)\n",
      "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.1.20)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.45)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.52 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.1.53)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.1.147)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.32.5)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.0.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain-community) (23.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain) (2.41.4)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain-community) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain-community) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain-community) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain-community) (2026.1.4)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.3.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community) (4.12.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-community langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_WXiA7nFmVmT",
    "outputId": "33a40d9d-b62f-43c9-b3e1-c78d5040a39f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.7)\n",
      "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (1.1.7)\n",
      "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.7 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.2.7)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.7)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (2.15.0)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.45)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.32.5)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.4)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (25.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (0.13.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (4.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (1.0.7)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (0.3.3)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (3.6.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.12.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2026.1.4)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.7->langchain) (3.0.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.7->langchain) (1.12.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain langchain-openai langchain-community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zAzZ4foTm4Un",
    "outputId": "92c1c1df-dac5-46a6-827a-85965f56918d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.7)\n",
      "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.36.0)\n",
      "Collecting huggingface_hub\n",
      "  Downloading huggingface_hub-1.3.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.7 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.2.7)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.7)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.45)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.32.5)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.4)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (3.20.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (0.28.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (25.0)\n",
      "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.5.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (0.21.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.15.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub) (4.12.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub) (0.16.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (1.33)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (0.13.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (4.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (1.0.7)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (0.3.3)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (3.6.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface_hub) (8.3.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.7->langchain) (3.0.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.7->langchain) (1.12.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
      "Downloading huggingface_hub-1.3.3-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.6/536.6 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: huggingface_hub\n",
      "  Attempting uninstall: huggingface_hub\n",
      "    Found existing installation: huggingface-hub 0.36.0\n",
      "    Uninstalling huggingface-hub-0.36.0:\n",
      "      Successfully uninstalled huggingface-hub-0.36.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "transformers 4.57.6 requires huggingface-hub<1.0,>=0.34.0, but you have huggingface-hub 1.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed huggingface_hub-1.3.3\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain langchain-community huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DwPb_ZWOnPOz"
   },
   "outputs": [],
   "source": [
    "from langchain_community.llms import HuggingFaceHub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 881
    },
    "id": "8sIg6GDBnYw0",
    "outputId": "d17c07cc-a1ce-4ed6-acfb-74e674aac4ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.6)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.3)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cpu)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2026.1.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
      "Downloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu, huggingface-hub\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface_hub 1.3.3\n",
      "    Uninstalling huggingface_hub-1.3.3:\n",
      "      Successfully uninstalled huggingface_hub-1.3.3\n",
      "Successfully installed faiss-cpu-1.13.2 huggingface-hub-0.36.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "4d523d3c7fff4628b2c3da1fd1568389",
       "pip_warning": {
        "packages": [
         "huggingface_hub"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install transformers faiss-cpu sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-XHXgrRVndcY"
   },
   "outputs": [],
   "source": [
    "!pip freeze > requirement.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2F13ALyMnw1o",
    "outputId": "8274c619-757e-4fde-b608-9c97e959793c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.7)\n",
      "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.14.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.5)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.7 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.2.7)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.7)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.45)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.4)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2026.1.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (25.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (0.13.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (4.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (1.0.7)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (0.3.3)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (3.6.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.12.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.7->langchain) (3.0.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.7->langchain) (1.12.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain langchain-community beautifulsoup4 requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gjI5VgLpn0PX",
    "outputId": "14e1bf6a-82cb-4693-cee6-0384279cba9f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
      "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "39oOuZhwnwWX",
    "outputId": "f0558854-9c87-45f9-b64b-8e8b4f961bdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.1/303.1 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langgraph-prebuilt 1.0.7 requires langchain-core>=1.0.0, but you have langchain-core 0.1.53 which is incompatible.\n",
      "langchain-classic 1.0.1 requires langchain-core<2.0.0,>=1.2.5, but you have langchain-core 0.1.53 which is incompatible.\n",
      "langchain-classic 1.0.1 requires langchain-text-splitters<2.0.0,>=1.1.0, but you have langchain-text-splitters 0.0.2 which is incompatible.\n",
      "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
      "rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
      "pytensor 2.36.3 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "xarray 2025.12.0 requires packaging>=24.1, but you have packaging 23.2 which is incompatible.\n",
      "langgraph-checkpoint 4.0.0 requires langchain-core>=0.2.38, but you have langchain-core 0.1.53 which is incompatible.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "google-cloud-bigquery 3.40.0 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\n",
      "google-adk 1.21.0 requires tenacity<10.0.0,>=9.0.0, but you have tenacity 8.5.0 which is incompatible.\n",
      "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "db-dtypes 1.5.0 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\n",
      "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip -q uninstall -y langchain langchain-community langchain-openai\n",
    "!pip -q install \"langchain<0.2.0\" beautifulsoup4 requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4hrhnRsxx-8z"
   },
   "source": [
    "Step 1: Loading\n",
    "\n",
    "Specify a DocumentLoader to load in unstructured data as Documents.\n",
    "\n",
    "\n",
    "A WebBaseLoader is used to load all text from HTML webpages into a document format that we can use for NLP tasks\n",
    "\n",
    "Loading the Web Document with LangChain\n",
    "\n",
    "Using LangChain’s WebBaseLoader to load the blog content directly from the URL. This:\n",
    "\n",
    "i. Fetches and parses the webpage\n",
    "\n",
    "ii. Strips out HTML tags\n",
    "\n",
    "iii. Returns clean, readable text stored in the data variable\n",
    "\n",
    "This allows us to work with real-world web content without manual preprocessing.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7LuqPkg8pPfC"
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"http://jalammar.github.io/illustrated-transformer/\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HROwM_KyyfjN"
   },
   "source": [
    "Step 2: Splitting\n",
    "\n",
    "Split the Document into chunks for embedding and vector storage.\n",
    "\n",
    "\n",
    "\n",
    "*   Vector Store: One of the most common ways to store and search over unstructured data is to embed it and store the resulting embedding vectors, and then at query time to embed the unstructured query and retrieve the embedding vectors that are 'most similar' to the embedded query.\n",
    "*   Text Embedding:  It is the process of converting text into a numerical representation, typically a vector (a list of numbers). Each word or subword in the text is mapped to a vector in such a way that similar words or phrases have similar vector representations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cNvhARHEpcyw"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 0) #Chunk Size=500: Each chunk will contain up to 500 characters. Chunk Overlap = 0, no overlap is introducted\n",
    "all_splits = text_splitter.split_documents(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gNLSDmmCzxrF"
   },
   "source": [
    "Step 3: Storing\n",
    "\n",
    "Embedding the contents of each document, then store the embedding and document in a vector store, with the embedding being used to index the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rui-McJPpfZK"
   },
   "outputs": [],
   "source": [
    "# Import FAISS from Langchain Vectorstore\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jLbOIF_ephu6"
   },
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406,
     "referenced_widgets": [
      "94a0881b350d46abac60d294fa34d917",
      "c1a2b9782ddf459688c9fc5949a44c92",
      "db18fc9ff6f2462883717ca32483bb8d",
      "f9ac403f9dbc4b94b73a947d9c7e1876",
      "db7f0b85b4c24cc2b0b6526efa5d0a5a",
      "55285b0feafc443f88740fe084f17d34",
      "957298eb5589417aac31adaacecdfd8b",
      "6a3f8a0d7a8b470d864deac909f2c4b9",
      "6e6dd873373a454a832a9bb9c267fecb",
      "8895cf346d5546bd80a8bfb8535bb6d8",
      "b92d066f9f3040ca88fb48a360a10de1",
      "d4aaa38956d240e689dcc2b3d0786d6f",
      "986890781f1c49c28c04d8d9fd2d71b4",
      "2b36a2b98fc54f439cd6587ed548a41c",
      "2a3e0736f2fe446ea7287eb7379e1c06",
      "ef22d314660242b2a0ae2a09973430a0",
      "7e8b885b649a47a3a43adf889f91bcf6",
      "fa834b2295054a89a555aaa31ca82b4b",
      "e37a82f0e363420b9c64f81c70bb30be",
      "9c62fdf5fdac4bce87784a966b26a8c9",
      "3dcbe4e8cf1f445290947ab9385d70ce",
      "a4ae6570c1d04d41a91f7c7ba854495e",
      "83da3c9ebcd64e3bbe080cfc6c1433d1",
      "e2df6386d74b4d38ac95caa4a9670374",
      "3f80ba0f05854e39a6fb9fde43733d16",
      "d3d8e50483a04d72b7d6280e11ff0d95",
      "846eacd50a3142aba54d54fb769c5c8f",
      "a96955b2883345948cc63f60ebf4a640",
      "41b80346d434499d94155d4a534e1935",
      "fecc69c06f1c4ca985fbc6cc435bb636",
      "001a99133c42480ab545efe837fcfa9c",
      "0a6a737bf3a94961a0319caf3f369fb7",
      "c3208b3361154d38b6c253e2d62eedee",
      "f77dfe2bb5a9478b86dbfebe6c0dd749",
      "694939533c49432fb0c35ec99440dd2e",
      "63d18c6a85684fea8f47c4f9f45d3713",
      "d857e0b81d564c3db6be5aa526f87c46",
      "b757c487717249868f3278e9ce3b0b45",
      "baa52d94a393445a83e15cb90ed2dec3",
      "efa7bb73d38c44a29ce3d9ff809e738a",
      "eeb7e0b175c14a0aa8f77216b118fafd",
      "2dbcccd86c6c4663877b0d27a51b8ea3",
      "78f6a14a5e2f4694925e815683dbeacf",
      "e4490cc8ce6c4e16a93214c7fb101991",
      "8762be9a6f5b44b4996ffe24ad2366ed",
      "5f26f29ddf2b4ed1a2d9ae9ce4785a49",
      "eb1c7f291c2c43b6b3d97f432981f6f7",
      "ced93f32ef5c4dcbb399ab5277e64dbf",
      "6898201b2d364590a8fe48b9198df9ac",
      "758b7e2c49314a0088081be20233053c",
      "75f4299f87464ac8b17b73c8d82c441a",
      "88ed7ce92a114d46bd159bdba1446f44",
      "a4a132478f42477b857e66ae0b6baf98",
      "9d90e1da48c4407799e70bc3f32a0ced",
      "f62692a47b7a4c3180e3036396357aec",
      "73533d0246484a6a8cc56eb1198c05f8",
      "0ff7bae901b84713acad52ab604e01a2",
      "fbf014ac65af4a7ab28c632604ffa98f",
      "0c7f4a463f7c402ea782376fb98cad68",
      "b38ebc731ba1414897938655a00407aa",
      "d773d06e0149443e825f556224277ce9",
      "16bc588b7f0c4798b38d4783c12a831c",
      "4a572856cb9244d788930295a3672ab9",
      "46c9d15b9a80476d934b4737e3db00a7",
      "3baa5c0242974eaaa9571e0ff51b657e",
      "ee6dbe531dcc44ca8145e4c261dd366f",
      "572b8ae404584780bbd53625b2c873b7",
      "36e485184a644b51916a1dd61442ea02",
      "47a6434a739a44dea471cc44c23698c2",
      "70204d9f4fdb43ee87dc8842b7a6f5bb",
      "5a3971a5d5da4f9cbffd2795e394b84d",
      "d0fda0362fc544e59b772ab5b3a51a76",
      "c3cafae3beda4038bcece78423f0cbdc",
      "82f2f36a9d7245cc8d960db757aaceee",
      "4ee15a7b779f404990da7912cde8a240",
      "06a6d878fb8b4fb8ad65af6710f782e1",
      "1129e2004fa7452f9883a8df29447112",
      "5558aef000e346b0af06ea6f4603b43f",
      "d59aa4c0a9d74212827b504dda600a7d",
      "f03e4344f7de4f379b04ccf990d820d3",
      "1248e7a7d3334f36b1a0a1e824b8b2d0",
      "b35a6f4c496349e29978de0b68da6fcc",
      "a04afded56dd472fa5afd9e4e95eefb8",
      "59b08c014a1642268e00b21be46fe216",
      "9c36d5b06d744a1983b97aea3b195852",
      "ab65901dc03a456b92fcb03943bad4e9",
      "102bada377364a0d8709064537f9f513",
      "c8683be9c59b4aa1b9039ac8c649f660",
      "a93c72f76946430681cf2da7b4512906",
      "0d54f0a7b8db405c9b38a2a211ef3452",
      "865ab8733d1941a9a12bd2b412c58220",
      "d063ba06f372426f8d9d5f76a9ff6525",
      "e30215adc26f428f8aad29ad4911ed73",
      "1492a8838b9f487eb6764fa16579ad71",
      "694ac1a01f354d25889f0004ee566acf",
      "58d6889474914744bc93b14239776f5e",
      "f75d40837e77411dbb44832336c2069b",
      "38bc1edcad6342d08936efe66ac421d1",
      "929ac31e84c843c9967c445a0dab4518",
      "189b8fa706a44fe9836349f521b38c11",
      "bc4eea23a54a41e6b8b92382a0b58995",
      "5430778bbc4b49d6b8a1e838348c544c",
      "0b5c65e4909d4409a305fa7abaa11be0",
      "f255e8fc6a734685945c2ea74149deaf",
      "82c2937671314af4abb483557ecd8af3",
      "556c7719e8f34fd89792f683f95c5908",
      "0b59e2dacda047c9923881080010a762",
      "f9247617a0214b93bb94f6f3a58e732b",
      "fe36aa13bdae4bd7aa462f5da9700879",
      "fb0be8d20d61441c993839f2cf625697",
      "a6a2d2ceb8ce41c7ab0d172f3f88f748",
      "56afd403688b45b4acd8ecae6ba5aeea",
      "294245a5b8184306a3efaea05f93f1c5",
      "424bd8c426024556a995e125b2bd6ace",
      "4c7f9de7a9234c04b946635cd1a73125",
      "88ad14beb4d54640a09ce7fe2a13dbc8",
      "55ffa5deb0ea4a24a4dd2b8b99951e51",
      "c4695967729e44ada695c74d878ba1d9",
      "5d7fd4f4963d441aa463d58806bca3e1",
      "2b6f5661b75d4005b69f1163923668e0",
      "8b706290f67b4953b4c7c519798a275f"
     ]
    },
    "id": "TPhjQdo2pj4A",
    "outputId": "10101793-a5d8-4e9c-da78-a1efdd21a0ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a0881b350d46abac60d294fa34d917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4aaa38956d240e689dcc2b3d0786d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83da3c9ebcd64e3bbe080cfc6c1433d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f77dfe2bb5a9478b86dbfebe6c0dd749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8762be9a6f5b44b4996ffe24ad2366ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73533d0246484a6a8cc56eb1198c05f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "572b8ae404584780bbd53625b2c873b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5558aef000e346b0af06ea6f4603b43f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93c72f76946430681cf2da7b4512906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "189b8fa706a44fe9836349f521b38c11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6a2d2ceb8ce41c7ab0d172f3f88f748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"sentence-transformers/all-mpnet-base-v2\" #to optimize for creating embeddings of sentences & text\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': False} #to prevent normalizaton of the embeddings\n",
    "hf = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iSKoh_FWpuUM"
   },
   "outputs": [],
   "source": [
    " # Creating a vector store\n",
    "vectorstore = FAISS.from_documents(documents=all_splits, embedding=hf) ## hf are the hugging face embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d55L60C008TX"
   },
   "source": [
    "Step 4: Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WuFjmGV0p2v9",
    "outputId": "1b82bcef-15f8-4975-99ec-0c44356f64a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Alammar, J (2018). The Illustrated Transformer [Blog post]. Retrieved from https://jalammar.github.io/illustrated-transformer/\\n\\nNote: If you translate any of the posts, let me know so I can link your translation to the original post. My email is in the about page.', metadata={'source': 'http://jalammar.github.io/illustrated-transformer/', 'title': 'The Illustrated Transformer – Jay Alammar – Visualizing machine learning one concept at a time.', 'description': \"Discussions:\\nHacker News (65 points, 4 comments), Reddit r/MachineLearning (29 points, 3 comments)\\n\\n\\nTranslations: Arabic, Chinese (Simplified) 1, Chinese (Simplified) 2, French 1, French 2, Italian, Japanese, Korean, Persian, Russian, Spanish 1, Spanish 2, Vietnamese\\n\\nWatch: MIT’s Deep Learning State of the Art lecture referencing this post\\n\\nFeatured in courses at Stanford, Harvard, MIT, Princeton, CMU and others\\n\\n\\n \\n  \\n\\n  \\n  Update: This post has now become a book! Check out LLM-book.com which contains (Chapter 3) an updated and expanded version of this post speaking about the latest Transformer models and how they've evolved in the seven years since the original Transformer (like Multi-Query Attention and RoPE Positional embeddings).\\n  \\n \\n\\n\\nIn the previous post, we looked at Attention – a ubiquitous method in modern deep learning models. Attention is a concept that helped improve the performance of neural machine translation applications. In this post, we will look at The Transformer – a model that uses attention to boost the speed with which these models can be trained. The Transformer outperforms the Google Neural Machine Translation model in specific tasks. The biggest benefit, however, comes from how The Transformer lends itself to parallelization. It is in fact Google Cloud’s recommendation to use The Transformer as a reference model to use their Cloud TPU offering. So let’s try to break the model apart and look at how it functions.\\n\\nThe Transformer was proposed in the paper Attention is All You Need. A TensorFlow implementation of it is available as a part of the Tensor2Tensor package. Harvard’s NLP group created a guide annotating the paper with PyTorch implementation. In this post, we will attempt to oversimplify things a bit and introduce the concepts one by one to hopefully make it easier to understand to people without in-depth knowledge of the subject matter.\\n\\n2025 Update: We’ve built a free short course that brings the contents of this post up-to-date with animations:\\n\\n\\n\\n\\nA High-Level Look\\nLet’s begin by looking at the model as a single black box. In a machine translation application, it would take a sentence in one language, and output its translation in another.\\n\\n\\n  \\n\\n\\n\", 'language': 'No language found.'}),\n",
       " Document(page_content='Go Forth And Transform\\nI hope you’ve found this a useful place to start to break the ice with the major concepts of the Transformer. If you want to go deeper, I’d suggest these next steps:', metadata={'source': 'http://jalammar.github.io/illustrated-transformer/', 'title': 'The Illustrated Transformer – Jay Alammar – Visualizing machine learning one concept at a time.', 'description': \"Discussions:\\nHacker News (65 points, 4 comments), Reddit r/MachineLearning (29 points, 3 comments)\\n\\n\\nTranslations: Arabic, Chinese (Simplified) 1, Chinese (Simplified) 2, French 1, French 2, Italian, Japanese, Korean, Persian, Russian, Spanish 1, Spanish 2, Vietnamese\\n\\nWatch: MIT’s Deep Learning State of the Art lecture referencing this post\\n\\nFeatured in courses at Stanford, Harvard, MIT, Princeton, CMU and others\\n\\n\\n \\n  \\n\\n  \\n  Update: This post has now become a book! Check out LLM-book.com which contains (Chapter 3) an updated and expanded version of this post speaking about the latest Transformer models and how they've evolved in the seven years since the original Transformer (like Multi-Query Attention and RoPE Positional embeddings).\\n  \\n \\n\\n\\nIn the previous post, we looked at Attention – a ubiquitous method in modern deep learning models. Attention is a concept that helped improve the performance of neural machine translation applications. In this post, we will look at The Transformer – a model that uses attention to boost the speed with which these models can be trained. The Transformer outperforms the Google Neural Machine Translation model in specific tasks. The biggest benefit, however, comes from how The Transformer lends itself to parallelization. It is in fact Google Cloud’s recommendation to use The Transformer as a reference model to use their Cloud TPU offering. So let’s try to break the model apart and look at how it functions.\\n\\nThe Transformer was proposed in the paper Attention is All You Need. A TensorFlow implementation of it is available as a part of the Tensor2Tensor package. Harvard’s NLP group created a guide annotating the paper with PyTorch implementation. In this post, we will attempt to oversimplify things a bit and introduce the concepts one by one to hopefully make it easier to understand to people without in-depth knowledge of the subject matter.\\n\\n2025 Update: We’ve built a free short course that brings the contents of this post up-to-date with animations:\\n\\n\\n\\n\\nA High-Level Look\\nLet’s begin by looking at the model as a single black box. In a machine translation application, it would take a sentence in one language, and output its translation in another.\\n\\n\\n  \\n\\n\\n\", 'language': 'No language found.'}),\n",
       " Document(page_content=\"Update: This post has now become a book! Check out LLM-book.com which contains (Chapter 3) an updated and expanded version of this post speaking about the latest Transformer models and how they've evolved in the seven years since the original Transformer (like Multi-Query Attention and RoPE Positional embeddings).\", metadata={'source': 'http://jalammar.github.io/illustrated-transformer/', 'title': 'The Illustrated Transformer – Jay Alammar – Visualizing machine learning one concept at a time.', 'description': \"Discussions:\\nHacker News (65 points, 4 comments), Reddit r/MachineLearning (29 points, 3 comments)\\n\\n\\nTranslations: Arabic, Chinese (Simplified) 1, Chinese (Simplified) 2, French 1, French 2, Italian, Japanese, Korean, Persian, Russian, Spanish 1, Spanish 2, Vietnamese\\n\\nWatch: MIT’s Deep Learning State of the Art lecture referencing this post\\n\\nFeatured in courses at Stanford, Harvard, MIT, Princeton, CMU and others\\n\\n\\n \\n  \\n\\n  \\n  Update: This post has now become a book! Check out LLM-book.com which contains (Chapter 3) an updated and expanded version of this post speaking about the latest Transformer models and how they've evolved in the seven years since the original Transformer (like Multi-Query Attention and RoPE Positional embeddings).\\n  \\n \\n\\n\\nIn the previous post, we looked at Attention – a ubiquitous method in modern deep learning models. Attention is a concept that helped improve the performance of neural machine translation applications. In this post, we will look at The Transformer – a model that uses attention to boost the speed with which these models can be trained. The Transformer outperforms the Google Neural Machine Translation model in specific tasks. The biggest benefit, however, comes from how The Transformer lends itself to parallelization. It is in fact Google Cloud’s recommendation to use The Transformer as a reference model to use their Cloud TPU offering. So let’s try to break the model apart and look at how it functions.\\n\\nThe Transformer was proposed in the paper Attention is All You Need. A TensorFlow implementation of it is available as a part of the Tensor2Tensor package. Harvard’s NLP group created a guide annotating the paper with PyTorch implementation. In this post, we will attempt to oversimplify things a bit and introduce the concepts one by one to hopefully make it easier to understand to people without in-depth knowledge of the subject matter.\\n\\n2025 Update: We’ve built a free short course that brings the contents of this post up-to-date with animations:\\n\\n\\n\\n\\nA High-Level Look\\nLet’s begin by looking at the model as a single black box. In a machine translation application, it would take a sentence in one language, and output its translation in another.\\n\\n\\n  \\n\\n\\n\", 'language': 'No language found.'}),\n",
       " Document(page_content='The Transformer was proposed in the paper Attention is All You Need. A TensorFlow implementation of it is available as a part of the Tensor2Tensor package. Harvard’s NLP group created a guide annotating the paper with PyTorch implementation. In this post, we will attempt to oversimplify things a bit and introduce the concepts one by one to hopefully make it easier to understand to people without in-depth knowledge of the subject matter.', metadata={'source': 'http://jalammar.github.io/illustrated-transformer/', 'title': 'The Illustrated Transformer – Jay Alammar – Visualizing machine learning one concept at a time.', 'description': \"Discussions:\\nHacker News (65 points, 4 comments), Reddit r/MachineLearning (29 points, 3 comments)\\n\\n\\nTranslations: Arabic, Chinese (Simplified) 1, Chinese (Simplified) 2, French 1, French 2, Italian, Japanese, Korean, Persian, Russian, Spanish 1, Spanish 2, Vietnamese\\n\\nWatch: MIT’s Deep Learning State of the Art lecture referencing this post\\n\\nFeatured in courses at Stanford, Harvard, MIT, Princeton, CMU and others\\n\\n\\n \\n  \\n\\n  \\n  Update: This post has now become a book! Check out LLM-book.com which contains (Chapter 3) an updated and expanded version of this post speaking about the latest Transformer models and how they've evolved in the seven years since the original Transformer (like Multi-Query Attention and RoPE Positional embeddings).\\n  \\n \\n\\n\\nIn the previous post, we looked at Attention – a ubiquitous method in modern deep learning models. Attention is a concept that helped improve the performance of neural machine translation applications. In this post, we will look at The Transformer – a model that uses attention to boost the speed with which these models can be trained. The Transformer outperforms the Google Neural Machine Translation model in specific tasks. The biggest benefit, however, comes from how The Transformer lends itself to parallelization. It is in fact Google Cloud’s recommendation to use The Transformer as a reference model to use their Cloud TPU offering. So let’s try to break the model apart and look at how it functions.\\n\\nThe Transformer was proposed in the paper Attention is All You Need. A TensorFlow implementation of it is available as a part of the Tensor2Tensor package. Harvard’s NLP group created a guide annotating the paper with PyTorch implementation. In this post, we will attempt to oversimplify things a bit and introduce the concepts one by one to hopefully make it easier to understand to people without in-depth knowledge of the subject matter.\\n\\n2025 Update: We’ve built a free short course that brings the contents of this post up-to-date with animations:\\n\\n\\n\\n\\nA High-Level Look\\nLet’s begin by looking at the model as a single black box. In a machine translation application, it would take a sentence in one language, and output its translation in another.\\n\\n\\n  \\n\\n\\n\", 'language': 'No language found.'})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are transformers?\"\n",
    "docs = vectorstore.similarity_search(question) #searching the vector store for the most relevant document chunks based on the similarity of their embeddings to the query's embedding.\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imFXi-8K1r4y"
   },
   "source": [
    "Step 5: Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8fI9mllkp4ay"
   },
   "outputs": [],
   "source": [
    "question = \"What are transformers?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258,
     "referenced_widgets": [
      "2af88ba4796848f4b8861490f9828ba6",
      "64e9ebb731524fa38188f4cbcfbcd84d",
      "c96596c09907412d95518f315ed8d8df",
      "051d04d04c894bfaa6c89aed9f4ff32a",
      "5086fe55dea544719d1dfd6a46b05ba0",
      "19e24448bb484d63a37766ecc624e520",
      "fda1498363cd4f9197f2afb40d424047",
      "f3a052d92ef041a6b32f9af9312099e4",
      "417e6c7784eb4158b22459c7d77a0902",
      "300d1c34d4f64592a895d09d63d98e14",
      "c35a2d7b8fdb441588e99f2b690f19df",
      "ceb4107582a54213a6ab1a2dc35cb99e",
      "754ecf0c102e493b8bb06db99950a8b0",
      "3671f989b00e48e692ec531b44fc88ea",
      "74cfce54727d4dc299b14b9304f1ea14",
      "b0d681e2598c4f7cbd0e43fa2fb5f704",
      "3bbfdfda15994e9e8fa8bfcf361c0c55",
      "6be75055c98a44d09988a53f093a7fb7",
      "2705a9cd74c34be99a3f234856c53924",
      "8ef0ed2503d24b54b8fbf8acd7575fdc",
      "7f91f6ecfcc44741ba1b66db67fafb95",
      "a2798cd9d23945e5871ce5d4092c2bcd",
      "6b8ca310bf1c4fdd82063c3ec30b4d62",
      "3867800e5c6642799b961804fb4d1967",
      "c95a5d7cb04847b49e0394985f806e32",
      "ab64779532e44d618de8eabe5cebfb2a",
      "733d0d0f0cfa496fb94dd11e7e31024a",
      "f6384078fe8c4d419949e89f456b82e4",
      "9a65c2cc5918453bae9413a941739c3c",
      "645ba7aee10b42a7b3ffde7aa5ad9883",
      "07fcd742e57e4cd09048e5a4b3e6c55a",
      "00201f9296c34241931f60c5f112b5dc",
      "6ef69216dd004bc1bf2cdc99073e49a2",
      "0f5be5ee3a5048e4b12cbc4efc3254a7",
      "7e895a32d5f9499fbcbd25f7d1897513",
      "b9900d5846b9486d92a99fa6144d63e7",
      "e5184ef106154a3eb931e5b28df4a03e",
      "9d4618c4a9054b63acccc06fd32cb9bf",
      "57f8dcb5d83940a8ab12866631340cdd",
      "33fc86e377ef4d1181b7e2e8a55c9b84",
      "3ff4080d21e045f39ea06ba9187684c0",
      "2fa9ae24b21744d1b413ffdc7c76dc22",
      "3d4e93fc78744455b048a1949f763a7e",
      "2a3caea7b6b24b6eab53a4e61fafbb18",
      "68623dd12da74504a33e89f418580aee",
      "4853d402dab24679b48b8c556aea004d",
      "0c76b7e869b2470dae963d58cbb7d26e",
      "45a1e8d3e7624456afbfcf4059401a95",
      "5b645a3b5cf447be848f8f0e07fec6d9",
      "09afbc0932664e5eb3c21fb585b157d4",
      "42e8fdb7c9d6426fba95120b69e63f44",
      "7bc9616f136d4aed89e59f5ba16ad201",
      "3bf9ff64a4374b568f45b4a916b55d79",
      "987523ea39f04345a697476929b5cc19",
      "dddf8284ab05498caf69795d8b1d1343",
      "ddd430fa246148da81f44dd07a9de9dc",
      "42db7ad7c1054055a295dd3d637435d3",
      "347c16e2a4714cc79222d18b43f0965a",
      "9ee98ebe4ffe4c9ea021e4b72113727b",
      "131573c6c56243f68aaf2827f24ff7ff",
      "599b0a3e5db54098ab13924c31cda2fa",
      "e570f92ad88745c58a4ef1cba2eb690b",
      "58fe5ecf49ce424c85289e930679002b",
      "fe20b8ef18f74861aee63dd5d0cd3c29",
      "5a7b223b64a249a8bb82835f011b550e",
      "8c36e1245a454620a7a41590134a7f04",
      "d507de579a384b469c008e5f7a3332a7",
      "35103cb5243546ff8ff37e90a3c39d17",
      "bcb64821eac843ada7e486e0fad26621",
      "b27b7917e0e84da5bc74c5a7df9ed0a6",
      "41a14786b5b74c0c8a6df107b9099f5b",
      "4920a22a87c34bbca7b2df9e801124c8",
      "acae0b43b2f14b61ad3950988e8cfc1d",
      "b5590c678cd14a94ad54932bebe79087",
      "36996d2172504dceba39d7c9d65158f8",
      "ef45a6d2d1ac4590a081fdf84de0c9ae",
      "8a5d19b84ab84d0d9aedbb635391c3d1"
     ]
    },
    "id": "wQoszV8ip8vS",
    "outputId": "e4f0767a-d4df-47e8-e0a5-563b6fd77e4b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2af88ba4796848f4b8861490f9828ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceb4107582a54213a6ab1a2dc35cb99e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b8ca310bf1c4fdd82063c3ec30b4d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f5be5ee3a5048e4b12cbc4efc3254a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68623dd12da74504a33e89f418580aee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd430fa246148da81f44dd07a9de9dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.13G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d507de579a384b469c008e5f7a3332a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"google/flan-t5-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# Define the pipeline\n",
    "hf_pipeline = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, max_length=512)\n",
    "\n",
    "# Wrap the pipeline in LangChain's LLM class\n",
    "llm = HuggingFacePipeline(pipeline=hf_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wwvTNY7fqAug",
    "outputId": "fe40cc69-f47c-4d11-e71e-89397b4ffbef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'What are transformers?',\n",
       " 'result': 'In this post, we will attempt to oversimplify things a bit and introduce the concepts one by one to hopefully make it easier to understand to people without in-depth knowledge of the subject matter.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(llm,retriever=vectorstore.as_retriever())\n",
    "qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CUxpVs9uqNeH",
    "outputId": "0fe2e808-b1d3-4457-a531-f1cab3e068c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': ' What is attention mechanism?', 'result': 'multi-headed'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \" What is attention mechanism?\"\n",
    "qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xAkxJUef2eqV"
   },
   "source": [
    "Step 6: Chat\n",
    "\n",
    "Conservation Summary Memory:  summarizes the conversation as it happens and stores the current summary in memory. This memory can then be used to inject the summary of the conversation so far into a prompt/chain. This memory is most useful for longer conversations, where keeping the past message history in the prompt verbatim would take up too many tokens.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AKRb_H2WqoRl"
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fwiztNxhqpNG"
   },
   "outputs": [],
   "source": [
    "memory = ConversationSummaryMemory(\n",
    "    llm=llm,\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sCzrWng2zMA"
   },
   "source": [
    "Conversational Retrieval Chain\n",
    "\n",
    "This is a type of chain for having a conversation based on retrieved documents. This chain takes in chat history (a list of messages) and new questions, and then returns an answer to that question. The algorithm for this chain consists of three parts:\n",
    "\n",
    "Use the chat history and the new question to create a “standalone question”. This is done so that this question can be passed into the retrieval step to fetch relevant documents. If only the new question was passed in, then the relevant context may be lacking. If the whole conversation was passed into retrieval, there may be unnecessary information there that would distract from retrieval.\n",
    "\n",
    "This new standalone question is passed to the retriever, and relevant documents are returned.\n",
    "\n",
    "The retrieved documents are passed to an LLM along with either the new question (default behavior) or the original question and chat history to generate a final response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4dpWjZqxqr7q"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "chat = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DxGhKLZDqs5x",
    "outputId": "1c9a3bb3-c7f1-474d-98d0-a39ffe959e7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "system: \n",
      "Follow Up Input: Explain self-attention\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "If you’re familiar with RNNs, think of how maintaining a hidden state allows an RNN to incorporate its representation of previous words/vectors it has processed with the current one it’s processing. Self-attention is the method the Transformer uses to bake the “understanding” of other relevant words into the one we’re currently processing.\n",
      "\n",
      "The second step in calculating self-attention is to calculate a score. Say we’re calculating the self-attention for the first word in this example, “Thinking”. We need to score each word of the input sentence against this word. The score determines how much focus to place on other parts of the input sentence as we encode a word at a certain position.\n",
      "\n",
      "Self-Attention at a High Level\n",
      "Don’t be fooled by me throwing around the word “self-attention” like it’s a concept everyone should be familiar with. I had personally never came across the concept until reading the Attention is All You Need paper. Let us distill how it works.\n",
      "Say the following sentence is an input sentence we want to translate:\n",
      "”The animal didn't cross the street because it was too tired”\n",
      "\n",
      "That’s pretty much all there is to multi-headed self-attention. It’s quite a handful of matrices, I realize. Let me try to put them all in one visual so we can look at them in one place\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Now that we have touched upon attention heads, let’s revisit our example from before to see where the different attention heads are focusing as we encode the word “it” in our example sentence:\n",
      "\n",
      "Question: What is self-attention?\n",
      "Helpful Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Explain self-attention',\n",
       " 'chat_history': [SystemMessage(content='')],\n",
       " 'answer': 'the method the Transformer uses to bake the “understanding” of other relevant words into the one we’re currently processing'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"Explain self-attention\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xjSyXGfvqu4D",
    "outputId": "26ac20ba-2104-4657-9b65-bcba3b17b9da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "system: Self-attention AI is the method the Transformer uses to bake the “understanding” of other relevant words into the one we’re currently processing.\n",
      "Follow Up Input: What is a gentler approach to transformers?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "Go Forth And Transform\n",
      "I hope you’ve found this a useful place to start to break the ice with the major concepts of the Transformer. If you want to go deeper, I’d suggest these next steps:\n",
      "\n",
      "Alammar, J (2018). The Illustrated Transformer [Blog post]. Retrieved from https://jalammar.github.io/illustrated-transformer/\n",
      "\n",
      "Note: If you translate any of the posts, let me know so I can link your translation to the original post. My email is in the about page.\n",
      "\n",
      "Update: This post has now become a book! Check out LLM-book.com which contains (Chapter 3) an updated and expanded version of this post speaking about the latest Transformer models and how they've evolved in the seven years since the original Transformer (like Multi-Query Attention and RoPE Positional embeddings).\n",
      "\n",
      "The Transformer was proposed in the paper Attention is All You Need. A TensorFlow implementation of it is available as a part of the Tensor2Tensor package. Harvard’s NLP group created a guide annotating the paper with PyTorch implementation. In this post, we will attempt to oversimplify things a bit and introduce the concepts one by one to hopefully make it easier to understand to people without in-depth knowledge of the subject matter.\n",
      "\n",
      "Question: What is a gentler approach to transformers?\n",
      "Helpful Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What is a gentler approach to transformers?',\n",
       " 'chat_history': [SystemMessage(content='Self-attention AI is the method the Transformer uses to bake the “understanding” of other relevant words into the one we’re currently processing.')],\n",
       " 'answer': 'In this post, we will attempt to oversimplify things a bit and introduce the concepts one by one to hopefully make it easier to understand to people without in-depth knowledge of the subject matter.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"What is a gentler approach to transformers?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mnMCEmnJrD8i",
    "outputId": "eae7cdb7-fad1-4116-98d2-6e1cc634611e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "system: In this post, we will attempt to oversimplify things a bit and introduce the concepts one by one to hopefully make it easier to understand to people without in-depth knowledge of the subject matter.\n",
      "Follow Up Input: Where were transformers proposed?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "Alammar, J (2018). The Illustrated Transformer [Blog post]. Retrieved from https://jalammar.github.io/illustrated-transformer/\n",
      "\n",
      "Note: If you translate any of the posts, let me know so I can link your translation to the original post. My email is in the about page.\n",
      "\n",
      "Go Forth And Transform\n",
      "I hope you’ve found this a useful place to start to break the ice with the major concepts of the Transformer. If you want to go deeper, I’d suggest these next steps:\n",
      "\n",
      "Update: This post has now become a book! Check out LLM-book.com which contains (Chapter 3) an updated and expanded version of this post speaking about the latest Transformer models and how they've evolved in the seven years since the original Transformer (like Multi-Query Attention and RoPE Positional embeddings).\n",
      "\n",
      "The Transformer was proposed in the paper Attention is All You Need. A TensorFlow implementation of it is available as a part of the Tensor2Tensor package. Harvard’s NLP group created a guide annotating the paper with PyTorch implementation. In this post, we will attempt to oversimplify things a bit and introduce the concepts one by one to hopefully make it easier to understand to people without in-depth knowledge of the subject matter.\n",
      "\n",
      "Question: In what country were transformers proposed?\n",
      "Helpful Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Where were transformers proposed?',\n",
       " 'chat_history': [SystemMessage(content='In this post, we will attempt to oversimplify things a bit and introduce the concepts one by one to hopefully make it easier to understand to people without in-depth knowledge of the subject matter.')],\n",
       " 'answer': 'not enough information'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"Where were transformers proposed?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CB04J-HqrMXB",
    "outputId": "376e8f8b-5075-4430-f150-71d96875177a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "system: Transformers were proposed in the early 20th century.\n",
      "Follow Up Input: What are the different layers in a typical Transformer model?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "Go Forth And Transform\n",
      "I hope you’ve found this a useful place to start to break the ice with the major concepts of the Transformer. If you want to go deeper, I’d suggest these next steps:\n",
      "\n",
      "Alammar, J (2018). The Illustrated Transformer [Blog post]. Retrieved from https://jalammar.github.io/illustrated-transformer/\n",
      "\n",
      "Note: If you translate any of the posts, let me know so I can link your translation to the original post. My email is in the about page.\n",
      "\n",
      "Update: This post has now become a book! Check out LLM-book.com which contains (Chapter 3) an updated and expanded version of this post speaking about the latest Transformer models and how they've evolved in the seven years since the original Transformer (like Multi-Query Attention and RoPE Positional embeddings).\n",
      "\n",
      "This goes for the sub-layers of the decoder as well. If we’re to think of a Transformer of 2 stacked encoders and decoders, it would look something like this:\n",
      "\n",
      "Question: What are the different layers in a typical Transformer model?\n",
      "Helpful Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What are the different layers in a typical Transformer model?',\n",
       " 'chat_history': [SystemMessage(content='Transformers were proposed in the early 20th century.')],\n",
       " 'answer': '2 stacked encoders and decoders'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"What are the different layers in a typical Transformer model?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3DcIhHBPrk_i",
    "outputId": "c0c6a718-038f-42d7-fe88-c998d7c76217"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "system: Transformers were proposed in the early 20th century.\n",
      "Follow Up Input: If the vocabulary is 10,000 words, what would the width of the logits vector?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "Let’s assume that our model knows 10,000 unique English words (our model’s “output vocabulary”) that it’s learned from its training dataset. This would make the logits vector 10,000 cells wide – each cell corresponding to the score of a unique word. That is how we interpret the output of the model followed by the Linear layer.\n",
      "\n",
      "To visualize this, let’s assume our output vocabulary only contains six words(“a”, “am”, “i”, “thanks”, “student”, and “<eos>” (short for ‘end of sentence’)).\n",
      "\n",
      "And so on, until the fifth output distribution indicates ‘<end of sentence>’ symbol, which also has a cell associated with it from the 10,000 element vocabulary.\n",
      "\n",
      "The output vocabulary of our model is created in the preprocessing phase before we even begin training.\n",
      " \n",
      "Once we define our output vocabulary, we can use a vector of the same width to indicate each word in our vocabulary. This also known as one-hot encoding. So for example, we can indicate the word “am” using the following vector:\n",
      "\n",
      "\n",
      "\n",
      "  Example: one-hot encoding of our output vocabulary\n",
      "\n",
      "Question: If the vocabulary is 10,000 words, what would the width of the logits vector be?\n",
      "Helpful Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'If the vocabulary is 10,000 words, what would the width of the logits vector?',\n",
       " 'chat_history': [SystemMessage(content='Transformers were proposed in the early 20th century.')],\n",
       " 'answer': '10,000 cells'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"If the vocabulary is 10,000 words, what would the width of the logits vector?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hlGrPGW1roZ2",
    "outputId": "1fb7de3c-a7c6-45e4-d0f4-86a728377701"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "system: The logits vector has a width of 10,000 cells.\n",
      "Follow Up Input: Explain the training process of a Transformer network in detail\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "Recap Of Training\n",
      "Now that we’ve covered the entire forward-pass process through a trained Transformer, it would be useful to glance at the intuition of training the model.\n",
      "During training, an untrained model would go through the exact same forward pass. But since we are training it on a labeled training dataset, we can compare its output with the actual correct output.\n",
      "\n",
      "Go Forth And Transform\n",
      "I hope you’ve found this a useful place to start to break the ice with the major concepts of the Transformer. If you want to go deeper, I’d suggest these next steps:\n",
      "\n",
      "The Transformer was proposed in the paper Attention is All You Need. A TensorFlow implementation of it is available as a part of the Tensor2Tensor package. Harvard’s NLP group created a guide annotating the paper with PyTorch implementation. In this post, we will attempt to oversimplify things a bit and introduce the concepts one by one to hopefully make it easier to understand to people without in-depth knowledge of the subject matter.\n",
      "\n",
      "The following steps repeat the process until a special  symbol is reached indicating the transformer decoder has completed its output. The output of each step is fed to the bottom decoder in the next time step, and the decoders bubble up their decoding results just like the encoders did. And just like we did with the encoder inputs, we embed and add positional encoding to those decoder inputs to indicate the position of each word.\n",
      "\n",
      "Question: What is the training process of a Transformer network?\n",
      "Helpful Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Explain the training process of a Transformer network in detail',\n",
       " 'chat_history': [SystemMessage(content='The logits vector has a width of 10,000 cells.')],\n",
       " 'answer': 'The output of each step is fed to the bottom decoder in the next time step, and the decoders bubble up their decoding results just like the encoders did. And just like we did with the encoder inputs, we embed and add positional encoding to those decoder inputs to indicate the position of each word.'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"Explain the training process of a Transformer network in detail\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQkavJRy3l2V"
   },
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "POSq71AOruOm",
    "outputId": "f6a64c3b-0129-4fbc-d6eb-4f5008f6585f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents: 1\n",
      "Average document length: 4199.0 words\n",
      "Minimum document length: 4199 words\n",
      "Maximum document length: 4199 words\n"
     ]
    }
   ],
   "source": [
    "# 1. Dataset Summary\n",
    "print(f\"Total documents: {len(data)}\")\n",
    "\n",
    "# Extract the text content from each Document object\n",
    "document_lengths = [len(doc.page_content.split()) for doc in data]  # Assuming 'data' is a list of Document objects\n",
    "\n",
    "# Display summary statistics\n",
    "print(f\"Average document length: {sum(document_lengths)/len(document_lengths)} words\")\n",
    "print(f\"Minimum document length: {min(document_lengths)} words\")\n",
    "print(f\"Maximum document length: {max(document_lengths)} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h1EhAACHr0wW",
    "outputId": "cd6e8471-82ba-4290-d693-5f27237c6e60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 5 sample documents:\n",
      "\n",
      "Sample 1:\n",
      "\n",
      "\n",
      "\n",
      "The Illustrated Transformer – Jay Alammar – Visualizing machine learning one concept at a time.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Jay Alammar\n",
      "Visualizing machine learning one concept at a time.Read our book, Hands-On Large Language Models and follow me on LinkedIn, Bluesky, Substack, X,YouTube \n",
      "\n",
      "\n",
      "Blog\n",
      "About\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Illustrated Transformer\n",
      "\n",
      "Discussions:\n",
      "Hacker News (65 points, 4 comments), Reddit r/MachineLearning (29 points, 3 comments)\n",
      "\n",
      "\n",
      "Translations: Arabic, Chinese (Simplified) 1, Chi\n"
     ]
    }
   ],
   "source": [
    "# 2. Text Sample Inspection\n",
    "sample_size = 5\n",
    "print(f\"Displaying {sample_size} sample documents:\")\n",
    "\n",
    "for i in range(min(sample_size, len(data))):\n",
    "    print(f\"\\nSample {i+1}:\")\n",
    "    print(data[i].page_content[:500])  # Display the first 500 characters of each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p2LI0bKnsNyd",
    "outputId": "20931202-576e-4516-ed5f-773eea5aaef2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (6058 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average token length: 6058.0 tokens\n",
      "Minimum token length: 6058 tokens\n",
      "Maximum token length: 6058 tokens\n"
     ]
    }
   ],
   "source": [
    "# 3. Tokenization\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load tokenizer for FLAN-T5 model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-large\")\n",
    "\n",
    "# Apply tokenizer and check token counts for first few documents\n",
    "tokenized_lengths = [len(tokenizer.tokenize(doc.page_content)) for doc in data]\n",
    "print(f\"Average token length: {sum(tokenized_lengths)/len(tokenized_lengths)} tokens\")\n",
    "print(f\"Minimum token length: {min(tokenized_lengths)} tokens\")\n",
    "print(f\"Maximum token length: {max(tokenized_lengths)} tokens\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 627
    },
    "id": "fzvUGV88spHe",
    "outputId": "5e8c536f-fdd4-4200-9ed2-69d38ad2e626"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4. Document Distribution Analysis\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the distribution of document lengths (in words) and token lengths\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Document length distribution\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(document_lengths, bins=20, color='skyblue', edgecolor='black')\n",
    "plt.title(\"Document Length Distribution (in Words)\")\n",
    "plt.xlabel(\"Word Count\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "# Token length distribution\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(tokenized_lengths, bins=20, color='lightgreen', edgecolor='black')\n",
    "plt.title(\"Token Length Distribution\")\n",
    "plt.xlabel(\"Token Count\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dT8E-thG3iMA"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21669,
     "status": "ok",
     "timestamp": 1769263077700,
     "user": {
      "displayName": "Ellie Wu",
      "userId": "06449904466312309703"
     },
     "user_tz": -660
    },
    "id": "JUGgN_N5S3qj",
    "outputId": "c1abb567-52cf-45a5-ce63-396384f72928"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418
    },
    "executionInfo": {
     "elapsed": 57,
     "status": "error",
     "timestamp": 1769263289168,
     "user": {
      "displayName": "Ellie Wu",
      "userId": "06449904466312309703"
     },
     "user_tz": -660
    },
    "id": "IUHby84KTANw",
    "outputId": "2e5ae2e3-86aa-4df4-dbcd-43dca8be0a47"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/LangChain_Dcoument_Q&A_.ipynb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nbformat/__init__.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(fp, as_version, capture_validation_error, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1272117170.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnbformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/Colab Notebooks/LangChain_Dcoument_Q&A_.ipynb\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnbformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"widgets\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"widgets_state\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nbformat/__init__.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(fp, as_version, capture_validation_error, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: PTH123\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mreads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapture_validation_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/LangChain_Dcoument_Q&A_.ipynb'"
     ]
    }
   ],
   "source": [
    "import nbformat\n",
    "path = \"/content/drive/MyDrive/Colab Notebooks/LangChain_Dcoument_Q&A_.ipynb\"\n",
    "nb = nbformat.read(path, as_version=4)\n",
    "nb.metadata.pop(\"widgets\", None)\n",
    "nb.metadata.pop(\"widgets_state\", None)\n",
    "nb.metadata.pop(\"widgets_state\", None)\n",
    "for cell in nb.cells:\n",
    "  cell.metadata.pop(\"widgets\", None)\n",
    "nbformat.write(nb, path)\n",
    "print(\"Cleaned notebook metadata for Github:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cJn-OrmbTsdf"
   },
   "outputs": [],
   "source": [
    "!find \"/content/drive/MyDrive\" - name \"*.ipynb\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
